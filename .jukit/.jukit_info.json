{"cmd": "import io\nimport json\nimport re\nimport warnings\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom os import listdir\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nimport xarray as xr\nfrom frites import set_mpl_style\nfrom IPython.display import HTML\nfrom matplotlib.animation import FuncAnimation\nfrom scipy import stats\nfrom scipy.stats import linregress, normaltest, pearsonr\n\nset_mpl_style()\n\n\ndef process_events(rows, blocks, colnames):\n    # If no data, create empty dataframe w/ all cols and types\n    if len(rows) == 0:\n        rows = [\"\", \"\"]\n        blocks = []\n    # Parse data, dropping useless first column\n    if len(rows) == 1:\n        list(rows).append(\"\")\n    # first col is event type, which we drop later\n    colnames = [\"type\"] + colnames\n    coltypes = get_coltypes(colnames)\n    df = pd.read_csv(\n        io.StringIO(\"\\n\".join(rows)),\n        delimiter=\"\\s+\",\n        header=None,\n        names=colnames,\n        na_values=\".\",\n        index_col=False,\n    )\n    df = df.iloc[:, 1:]  # drop the first column\n    # Move eye column to end & make factor, append block numbers to beginning of data frame\n    if \"eye\" in colnames:\n        df = df.iloc[:, [1] + list(range(2, df.shape[1])) + [0]]\n        df[\"eye\"] = pd.Categorical(df[\"eye\"], categories=[\"L\", \"R\"], ordered=False)\n    df.insert(loc=0, column=\"trial\", value=blocks)\n    return df\n\n\ndef process_saccades(saccades, blocks, info):\n    sacc_df = process_events(saccades, blocks, get_sacc_header(info))\n    # Set amplitudes for any saccades missing start/end coords to NAs because they're wonky\n    ampl_cols = [col for col in sacc_df.columns if re.search(r\"ampl\\d*$\", col)]\n    partial = sacc_df[\"sxp\"].isna() | sacc_df[\"exp\"].isna()\n    if any(partial):\n        sacc_df.loc[partial, ampl_cols] = pd.NA\n    return sacc_df\n\n\ndef process_fixations(fixations, blocks, info):\n    return process_events(fixations, blocks, get_fix_header(info))\n\n\ndef process_blinks(blinks, blocks):\n    return process_events(blinks, blocks, [\"eye\", \"stime\", \"etime\", \"dur\"])\n\n\ndef process_messages(msgs, blocks):\n    # Process messages from tracker\n    msg_mat = [msg.split(\" \", 1) for msg in msgs]\n    msg_mat = [[msg[0][4:], msg[1]] for msg in msg_mat]\n    msg_df = pd.DataFrame(msg_mat, columns=[\"time\", \"text\"])\n    msg_df[\"time\"] = pd.to_numeric(msg_df[\"time\"])\n\n    # Append trial numbers to beginning of data frame\n    msg_df.insert(0, \"trial\", blocks)\n\n    return msg_df\n\n\ndef process_input(input_data, blocks):\n    return process_events(input_data, blocks, [\"time\", \"value\"])\n\n\ndef process_buttons(button, blocks):\n    return process_events(button, blocks, [\"time\", \"button\", \"state\"])\n\n\ndef from_header(header, field):\n    pattern = r\"\\*\\* {}\\s*: (.*)\".format(re.escape(field))\n    matches = [re.findall(pattern, line) for line in header]\n    matches = [match for match in matches if match]\n    return matches[0][0] if matches else None\n\n\ndef get_resolution(nonsample):\n    res = [None, None]\n    for pattern in [\"DISPLAY_COORDS\", \"GAZE_COORDS\", \"RESOLUTION\"]:\n        display_xy = [x for x in nonsample if pattern in x]\n        if len(display_xy) == 0:\n            continue\n        display_xy = re.sub(f\".* {pattern}\\\\D+(.*)\", \"\\\\1\", display_xy[0])\n        display_xy = [int(x) for x in re.split(\"\\\\s+\", display_xy)]\n        res = [display_xy[2] - display_xy[0] + 1, display_xy[3] - display_xy[1] + 1]\n        break\n    return res\n\n\ndef get_resolution(nonsample):\n    res = [None, None]\n    for pattern in [\"DISPLAY_COORDS\", \"GAZE_COORDS\", \"RESOLUTION\"]:\n        display_xy = [s for s in nonsample if pattern in s]\n        if len(display_xy) == 0:\n            continue\n        display_xy = re.sub(f\".* {pattern}\\\\D+(.*)\", \"\\\\1\", display_xy[0])\n        try:\n            display_xy = [int(float(s)) for s in display_xy.split()]\n        except ValueError:\n            continue\n        res = [display_xy[2] - display_xy[0] + 1, display_xy[3] - display_xy[1] + 1]\n        break\n    return res\n\n\ndef get_mount(mount_str):\n    # Older EyeLink 1000s may be missing \"R\" in table mount names, we add one if needed\n    if re.search(\"TABLE$\", mount_str):\n        mount_str = mount_str + \"R\"\n\n    mounts = {\n        \"MTABLER\": \"Desktop / Monocular / Head Stabilized\",\n        \"BTABLER\": \"Desktop / Binocular / Head Stabilized\",\n        \"RTABLER\": \"Desktop / Monocular / Remote\",\n        \"RBTABLER\": \"Desktop / Binocular / Remote\",\n        \"AMTABLER\": \"Arm Mount / Monocular / Head Stabilized\",\n        \"ARTABLER\": \"Arm Mount / Monocular / Remote\",\n        \"TOWER\": \"Tower Mount / Monocular / Head Stabilized\",\n        \"BTOWER\": \"Tower Mount / Binocular / Head Stabilized\",\n        \"MPRIM\": \"Primate Mount / Monocular / Head Stabilized\",\n        \"BPRIM\": \"Primate Mount / Binocular / Head Stabilized\",\n        \"MLRR\": \"Long-Range Mount / Monocular / Head Stabilized\",\n        \"BLRR\": \"Long-Range Mount / Binocular / Head Stabilized\",\n    }\n\n    return mounts[mount_str] if mount_str in mounts else None\n\n\ndef get_raw_header(info):\n    eyev = [\"xp\", \"yp\", \"ps\"]\n\n    if not info[\"mono\"]:\n        eyev = [f\"{e}{s}\" for s in [\"l\", \"r\"] for e in eyev]\n\n    if info[\"velocity\"]:\n        if info[\"mono\"]:\n            eyev += [\"xv\", \"yv\"]\n        else:\n            eyev += [f\"{e}{s}\" for s in [\"vl\", \"vr\"] for e in [\"x\", \"y\"]]\n\n    if info[\"resolution\"]:\n        eyev += [\"xr\", \"yr\"]\n\n    if info[\"input\"]:\n        eyev += [\"input\"]\n\n    if info[\"buttons\"]:\n        eyev += [\"buttons\"]\n\n    if info[\"tracking\"]:\n        eyev += [\"cr.info\"]\n\n    if info[\"htarg\"]:\n        eyev += [\"tx\", \"ty\", \"td\", \"remote.info\"]\n\n    return [\"time\"] + eyev\n\n\ndef get_event_header(info, xy_cols):\n    base = [\"eye\", \"stime\", \"etime\", \"dur\"]\n\n    if info[\"event.dtype\"] == \"HREF\":\n        xy_cols = [f\"href.{xy}\" for xy in xy_cols] + xy_cols\n\n    if info[\"resolution\"]:\n        xy_cols += [\"xr\", \"yr\"]\n\n    return base + xy_cols\n\n\ndef get_sacc_header(info):\n    return get_event_header(info, [\"sxp\", \"syp\", \"exp\", \"eyp\", \"ampl\", \"pv\"])\n\n\ndef get_fix_header(info):\n    return get_event_header(info, [\"axp\", \"ayp\", \"aps\"])\n\n\ndef get_model(header):\n    version_str = from_header(header, \"VERSION\")\n    version_str2 = [x for x in header if re.search(\"\\\\*\\\\* EYELINK II\", x)]\n    if version_str is None:\n        model = \"Unknown\"\n        ver_num = \"Unknown\"\n    elif version_str != \"EYELINK II 1\":\n        model = \"EyeLink I\"\n        ver_num = re.search(r\"(\\d+.\\d+)\", version_str).group(1)\n    else:\n        ver_num = re.search(r\"v(\\d+.\\d+)\", version_str2[0]).group(1)\n        model = (\n            \"EyeLink II\"\n            if float(ver_num) < 2.4\n            else \"EyeLink 1000\"\n            if float(ver_num) < 5\n            else \"EyeLink 1000 Plus\"\n            if float(ver_num) < 6\n            else \"EyeLink Portable Duo\"\n        )\n    return [model, ver_num]\n\n\ndef get_coltypes(colnames, float_time=True):\n    chr_cols = [\"type\", \"eye\", \"cr.info\", \"remote.info\"]\n    int_cols = [\"button\", \"state\", \"value\"]\n    time_cols = [\"time\", \"stime\", \"etime\", \"dur\"]\n    if not float_time:\n        int_cols += time_cols\n\n    coltypes = [\n        \"str\" if col in chr_cols else \"int64\" if col in int_cols else \"float64\"\n        for col in colnames\n    ]\n\n    return coltypes\n\n\ndef get_htarg_regex(binocular):\n    htarg_errs = \"MANCFTBLRTBLRTBLR\" if binocular else \"MANCFTBLRTBLR\"\n    htarg_errs = list(htarg_errs)\n    htarg_regex = \"(\" + \"|\".join(htarg_errs + [\"\\\\.\"]) + \")\"\n\n    return htarg_regex\n\n\ndef is_float(string):\n    return bool(re.search(\"\\\\.\", string))\n\n\ndef get_info(nonsample, firstcol):\n    header = [f for f in nonsample if f.startswith(\"**\")]\n    info = {}\n\n    # Get date/time of recording from file\n    datetime.strptime(from_header(header, \"DATE\"), \"%a %b %d %H:%M:%S %Y\")\n    # Get tracker model/version info\n    version_info = get_model(header)\n    info[\"model\"] = version_info[0]\n    info[\"version\"] = version_info[1]\n\n    # Get tracker mount info\n    elclcfg = [line for line in nonsample if \"ELCLCFG\" in line]\n    if len(elclcfg) > 0:\n        info[\"mount\"] = get_mount(re.findall(r\"ELCLCFG\\s+(.*)\", elclcfg[0])[0])\n\n    # Get display size from file\n    screen_res = get_resolution(nonsample)\n    info[\"screen.x\"] = screen_res[0]\n    info[\"screen.y\"] = screen_res[1]\n\n    # Get pupil size data type (area or diameter)\n    pupil_config = [line for i, line in enumerate(nonsample) if firstcol[i] == \"PUPIL\"]\n    if len(pupil_config) > 0:\n        info[\"pupil.dtype\"] = pupil_config[-1].split()[1]\n\n    # Find the samples and events config lines in the non-sample input, get data types\n    events_config = [\n        line for i, line in enumerate(nonsample) if firstcol[i] == \"EVENTS\"\n    ]\n    samples_config = [\n        line for i, line in enumerate(nonsample) if firstcol[i] == \"SAMPLES\"\n    ]\n\n    # Find the samples and events config lines in the non-sample input, get data types\n    events_config = [\n        line for i, line in enumerate(nonsample) if firstcol[i] == \"EVENTS\"\n    ]\n    samples_config = [\n        line for i, line in enumerate(nonsample) if firstcol[i] == \"SAMPLES\"\n    ]\n    if len(events_config) > 0:\n        info[\"event.dtype\"] = events_config[-1].split()[1]\n    if len(samples_config) > 0:\n        info[\"sample.dtype\"] = samples_config[-1].split()[1]\n\n    # Get last config line in file (preferring sample config) and extract remaining info\n    config = events_config + samples_config[-1:]\n    config = config[-1] if len(config) > 0 else \"\"\n    if config:\n        info[\"sample.rate\"] = (\n            float(re.findall(r\"RATE\\s+([0-9]+\\.[0-9]+)\", config)[0])\n            if \"RATE\" in config\n            else None\n        )\n        info[\"tracking\"] = \"\\tTRACKING\" in config\n        info[\"cr\"] = \"\\tCR\" in config\n        info[\"filter.level\"] = (\n            int(re.findall(r\"FILTER\\s+([0-9]+)\", config)[0])\n            if \"FILTER\" in config\n            else None\n        )\n        info[\"velocity\"] = \"\\tVEL\" in config\n        info[\"resolution\"] = \"\\tRES\" in config\n        info[\"htarg\"] = \"\\tHTARG\" in config\n        info[\"input\"] = \"\\tINPUT\" in config\n        info[\"buttons\"] = \"\\tBUTTONS\" in config\n        info[\"left\"] = \"\\tLEFT\" in config\n        info[\"right\"] = \"\\tRIGHT\" in config\n        info[\"mono\"] = not (info[\"right\"] & info[\"left\"])\n\n    return info\n\n\ndef process_raw(raw, blocks, info):\n    if len(raw) == 0:\n        # If no sample data in file, create empty raw DataFrame w/ all applicable columns\n        raw = [\"\", \"\"]\n        blocks = pd.Series([], dtype=int)\n        colnames = get_raw_header(info)\n        coltypes = get_coltypes(colnames, float_time=False)\n    else:\n        # Determine if timestamps stored as floats (edf2asc option -ftime, useful for 2000 Hz)\n        float_time = is_float(re.split(r\"\\s+\", raw[0])[0])\n        # Generate column names and types based in info in header\n        colnames = get_raw_header(info)\n        coltypes = get_coltypes(colnames, float_time)\n        # Discard any rows with too many or too few columns (usually rows where eye is missing)\n        row_length = [len(re.split(r\"\\t\", r)) for r in raw]\n        med_length = np.median(row_length)\n        raw = [r for r, l in zip(raw, row_length) if l == med_length]\n        blocks = blocks[row_length == med_length]\n        # Verify that generated columns match up with actual maximum row length\n        length_diff = med_length - len(colnames)\n        # if length_diff > 0:\n        #    warnings.warn(\"Unknown columns in raw data. Assuming first one is time, please check the others\")\n        #    colnames = [\"time\"] + [f\"X{i+1}\" for i in range(med_length-1)]\n        #    coltypes = \"i\" + \"?\"*(med_length-1)\n    # Process raw sample data using pandas\n    if len(raw) == 1:\n        raw.append(\"\")\n\n    raw_df = pd.read_csv(\n        io.StringIO(\"\".join(raw)),\n        sep=\"\\t\",\n        header=None,\n        names=colnames,\n        na_values=np.nan,\n        low_memory=False,\n    )\n\n    if info[\"tracking\"] and not info[\"cr\"]:\n        # Drop CR column when not actually used\n        raw_df = raw_df.drop(columns=[\"cr.info\"])\n    # Append block numbers to beginning of DataFrame\n    raw_df.insert(0, \"trial\", blocks)\n    # Replace missing pupil data (zeros) with NaNs\n    if \"X1\" not in raw_df.columns:\n        if info[\"mono\"]:\n            raw_df.loc[raw_df[\"ps\"] == 0, \"ps\"] = np.nan\n        else:\n            raw_df.loc[raw_df[\"psl\"] == 0, \"psl\"] = np.nan\n            raw_df.loc[raw_df[\"psr\"] == 0, \"psr\"] = np.nan\n    return raw_df\n\n\ndef read_asc(fname, samples=True, events=True, parse_all=False):\n    with open(fname, \"r\") as f:\n        inp = f.readlines()\n\n    # Convert to ASCII\n    inp = [line.encode(\"ascii\", \"ignore\").decode() for line in inp]\n\n    # Get strings prior to first tab for each line for faster string matching\n    inp_first = [re.split(r\"\\s\", s)[0] for s in inp]\n\n    # Get the Trial info for each trial:\n    bias = [\n        s.split()[4] for s in inp if len(s.split()) > 4 and s.split()[2] == \"Trialinfo:\"\n    ]\n    direct = [\n        s.split()[5] for s in inp if len(s.split()) > 4 and s.split()[2] == \"Trialinfo:\"\n    ]\n    # Check if any actual data recorded in file\n    starts = [i for i, x in enumerate(inp_first) if x == \"START\"]\n    if not starts:\n        raise ValueError(\"No samples or events found in .asc file.\")\n\n    # Read metadata from file before processing\n    is_raw = [bool(re.match(\"^[0-9]\", line)) for line in inp_first]\n\n    info = get_info(\n        [line for line, raw in zip(inp, is_raw) if not raw],\n        [first for first, raw in zip(inp_first, is_raw) if not raw],\n    )\n\n    # Do some extra processing/sanitizing if there's HTARG info in the file\n    if info[\"htarg\"]:\n        inp, info = handle_htarg(inp, info, is_raw)\n\n    # Find blocks and mark lines between block ENDs and next block STARTs\n    dividers = starts + [len(inp)]\n    block = np.cumsum([x == \"START\" for x in inp_first])\n    block = block.astype(float)\n\n    for i in range(1, len(dividers)):\n        start = dividers[i - 1]\n        end = dividers[i]\n        endline = [j for j, x in enumerate(inp_first[start:end]) if x == \"END\"]\n        if endline and endline[-1] < end - start:\n            block[endline[0] + start : end] += 0.5\n\n    # Unless parsing all input, drop any lines not within a block\n    block[: dividers[0] + 1] += 0.5\n    if not parse_all:\n        in_block = np.floor(block) == block\n        inp = [line for line, block_match in zip(inp, in_block) if block_match]\n        inp_first = [\n            first for first, block_match in zip(inp_first, in_block) if block_match\n        ]\n        is_raw = [raw for raw, block_match in zip(is_raw, in_block) if block_match]\n        block = block[in_block]\n\n    block = np.array(block)\n\n    # Initialize dictionary of data output and process different data types\n    out = {}\n    if samples:\n        out[\"raw\"] = process_raw(\n            [line for line, raw in zip(inp, is_raw) if raw], block[is_raw], info\n        )\n    if events:\n        is_sacc = np.array(inp_first) == \"ESACC\"\n        out[\"sacc\"] = process_saccades(\n            np.array(inp)[is_sacc], np.array(block)[is_sacc], info\n        )\n\n        is_fix = np.array(inp_first) == \"EFIX\"\n        out[\"fix\"] = process_fixations(\n            np.array(inp)[is_fix], np.array(block)[is_fix], info\n        )\n\n        is_blink = np.array(inp_first) == \"EBLINK\"\n        out[\"blinks\"] = process_blinks(\n            np.array(inp)[is_blink], np.array(block)[is_blink]\n        )\n\n        is_msg = np.array(inp_first) == \"MSG\"\n        out[\"msg\"] = process_messages(np.array(inp)[is_msg], np.array(block)[is_msg])\n\n        is_input = np.array(inp_first) == \"INPUT\"\n        out[\"input\"] = process_input(np.array(inp)[is_input], np.array(block)[is_input])\n\n        is_button = np.array(inp_first) == \"BUTTON\"\n        out[\"button\"] = process_buttons(\n            np.array(inp)[is_button], np.array(block)[is_button]\n        )\n\n    # needed for parsing, but otherwise redundant with CR\n    info[\"tracking\"] = None\n\n    out[\"info\"] = info\n\n    return out, np.array(bias, dtype=\"int\"), np.array(direct, dtype=\"int\") % 2\n\n\npath = \"/Volumes/oueld-kadd.h/Shared/HAMZA_PhD/Data/Probant_DevAsd/DATA/Controles/\"\n\ncategories = np.sort([f for f in listdir(path)])\nnamesCat = []\nfor cat in categories:\n    namesCat.append(np.sort([f for f in listdir(path + cat)]))\n\n\nallFiles = []\n\nfor nameCat, cat in zip(namesCat, categories):\n    filesCat = []\n    for name in nameCat:\n        files = np.sort([f for f in listdir(path + cat + \"/\" + name)])\n        filesCat.append(files)\n    allFiles.append(filesCat)\n\n\nallPaths = []\nfor cat, names, conditions in zip(categories, namesCat, allFiles):\n    catPaths = []\n    for name, namecond in zip(names, conditions):\n        for condition in namecond:\n            catPaths.append(path + cat + \"/\" + name + \"/\" + condition)\n    allPaths.append(catPaths)\n\n\nmeanPos = []\nstdPos = []\n\n\nmeanVelo = []\nstdVelo = []\n\n\nswitch = []\n\nProbas = []\nDirections = []\n\nTS = []\nSaccD = []\nSACC= []\n#Stimulus o\nSON=[]\n#Stimulus off\nSOFF=[]\nfor path in allPaths:\n    for f in path:\n        data, bias, direct = read_asc(f)\n\n        # Getting the probability from the name of the file\n        proba = int(f[-6:-4]) / 100  # probability\n        if proba == 0.0:\n            proba = 1\n\n        df = data[\"raw\"]\n\n        # Checking if the experiment was binorcular or monocular\n        mono = data[\"info\"][\"mono\"]\n        # Putting all the data in the right format\n        df[\"trial\"] = pd.to_numeric(df[\"trial\"], errors=\"coerce\")\n        df[\"time\"] = pd.to_numeric(df[\"time\"], errors=\"coerce\")\n        if not mono:\n            df[\"xpl\"] = pd.to_numeric(df[\"xpl\"], errors=\"coerce\")\n            df[\"ypl\"] = pd.to_numeric(df[\"ypl\"], errors=\"coerce\")\n            df[\"psl\"] = pd.to_numeric(df[\"psl\"], errors=\"coerce\")\n            df[\"xpr\"] = pd.to_numeric(df[\"xpr\"], errors=\"coerce\")\n            df[\"ypr\"] = pd.to_numeric(df[\"ypr\"], errors=\"coerce\")\n            df[\"psr\"] = pd.to_numeric(df[\"psr\"], errors=\"coerce\")\n        else:\n            df[\"xp\"] = pd.to_numeric(df[\"xp\"], errors=\"coerce\")\n            df[\"ypl\"] = pd.to_numeric(df[\"yp\"], errors=\"coerce\")\n            df[\"ps\"] = pd.to_numeric(df[\"ps\"], errors=\"coerce\")\n\n        df[\"input\"] = pd.to_numeric(df[\"input\"], errors=\"coerce\")\n\n        # Messages from eyelink:\n        MSG = data[\"msg\"]\n        tON = MSG.loc[MSG.text == \"StimulusOn\\n\", \"time\"]\n        t0 = MSG.loc[MSG.text == \"StimulusOff\\n\", \"time\"]\n        Zero = MSG.loc[MSG.text == \"TargetOn\\n\", [\"trial\", \"time\"]]\n        #Resetting t0 and tON\n        t0=t0.time.values-Zero.time.values\n        tON=tON.time.values-Zero.time.values\n        SON.append(tON)\n        SOFF.append(t0)\n        # resetting the time\n        for i in range(len(Zero)):\n            df.loc[df[\"trial\"] == i + 1, \"time\"] = (\n                df.loc[df[\"trial\"] == i + 1, \"time\"] - Zero.time.values[i]\n            )\n\n        # Getting the saccades:\n        Sacc = data[\"sacc\"]\n\n        # Resetting the saccades\n        for t in Zero.trial:\n            Sacc.loc[Sacc.trial == t, [\"stime\", \"etime\"]] = (\n                Sacc.loc[Sacc.trial == t, [\"stime\", \"etime\"]].values\n                - Zero.loc[Zero.trial == t, \"time\"].values\n            )\n\n        # Getting the trials where the saccades happens inside the time window. 0 and 80ms.\n        trialSacc = Sacc[(Sacc.stime >= -300) & (Sacc.etime < 80) & (Sacc.eye == \"R\")][\n            \"trial\"\n        ].values\n\n        saccDir = np.sign(\n            (\n                Sacc[(Sacc.stime >= -300) & (Sacc.etime < 80) & (Sacc.eye == \"R\")].exp\n                - Sacc[(Sacc.stime >=-300) & (Sacc.etime < 80) & (Sacc.eye == \"R\")].sxp\n            ).values\n        )\n\n        for t in Sacc.trial.unique():\n            start = Sacc.loc[(Sacc.trial == t) & (Sacc.eye == \"R\"), \"stime\"]\n            end = Sacc.loc[(Sacc.trial == t) & (Sacc.eye == \"R\"), \"etime\"]\n\n            for i in range(len(start)):\n                if not mono:\n                    df.loc[\n                        (df.trial == t)\n                        & (df.time >= start.iloc[i] - 20)\n                        & (df.time <= end.iloc[i] + 20),\n                        \"xpr\",\n                    ] = np.nan\n\n                else:\n                    df.loc[\n                        (df.trial == t)\n                        & (df.time >= start.iloc[i] - 20)\n                        & (df.time <= end.iloc[i] + 20),\n                        \"xp\",\n                    ] = np.nan\n\n        # first porbability switch\n        first_bias = np.where(bias == 1)[0][0]\n        switch.append(first_bias)\n\n        if not mono:\n            # Select the desired values\n            selected_values = df.xpr[(df.time >= 80) & (df.time <= 120)]\n\n            # print(len(selected_values))\n\n            # Rescale the position:\n            pos_before = df.xpr[(df.time >= -40) & (df.time <= 0)]\n\n            # Reshape into a 2D matrix\n            time_dim = 41\n\n            trial_dim = len(selected_values) // time_dim\n\n            # Re-basing the position\n            pos = np.array(selected_values[: time_dim * trial_dim]).reshape(\n                trial_dim, time_dim\n            )\n            # variance of pos on bias and non bias trials\n            stdPos.append(np.std(pos, axis=1) / 30)\n            pos_before_reshaped = np.array(pos_before[: time_dim * trial_dim]).reshape(\n                trial_dim, time_dim\n            )\n            pos_before_mean = np.nanmean(pos_before_reshaped, axis=1)\n\n            velo = np.gradient(pos, axis=1) * 1000 / 30\n            velo[(velo > 30) | (velo < -30)] = np.nan\n        #Smoothing velocity\n                \n            for i, pp in enumerate(pos_before_mean):\n                if pp == np.nan:\n                    pos[i] = np.nan\n                else:\n                    pos[i] = (pos[i] - pp) / 30\n\n            # pos=(pos-pos_before_mean.reshape(-1, 1))/30\n            pos[(pos > 3) | (pos < -3)] = np.nan\n\n        else:\n            # Select the desired values\n            selected_values = df.xp[(df.time >= 80) & (df.time <= 120)]\n            # print(len(selected_values))\n\n            # Rescale the position:\n            pos_before = df.xp[(df.time >= -40) & (df.time <= 0)]\n\n            # Reshape into a 2D matrix\n            time_dim = 41\n\n            trial_dim = len(selected_values) // time_dim\n\n            pos = np.array(selected_values[: time_dim * trial_dim]).reshape(\n                trial_dim, time_dim\n            )\n            stdPos.append(np.std(pos, axis=1) / 30)\n            pos_before_reshaped = np.array(pos_before[: time_dim * trial_dim]).reshape(\n                trial_dim, time_dim\n            )\n            pos_before_mean = np.nanmean(pos_before_reshaped, axis=1)\n\n            velo = np.gradient(pos, axis=1) * 1000 / 30\n            velo[(velo > 30) | (velo < -30)] = np.nan\n\n            for i, pp in enumerate(pos_before_mean):\n                if pp == np.nan:\n                    pos[i] = np.nan\n                else:\n                    pos[i] = (pos[i] - pp) / 30\n\n            # pos=(pos-pos_before_mean.reshape(-1, 1))/30\n            pos[(pos > 3) | (pos < -3)] = np.nan\n\n        # mean pos on bias and non bias trials for time window 80,120\n        meanPos.append(np.mean(pos, axis=1))\n\n        # mean of velocity on bias and non bias trials\n        meanVelo.append(np.mean(velo, axis=1))\n\n        # var of velocity on bias and non bias trials\n        stdVelo.append(np.std(velo, axis=1))\n\n        # subjects.append(name)\n\n        Probas.append(proba)\n\n        # Adding target directions\n\n        Directions.append(direct)\n\n        # Trials where there is a saccade in the time window [0, 80ms]\n\n        TS.append(trialSacc)\n\n        # Direction of the saccad\n\n        SaccD.append(saccDir)\n\n        SACC.append(Sacc)\ndf = pd.DataFrame(\n    {\n        \"meanPos\": meanPos,\n        \"stdPos\": stdPos,\n        \"meanVelo\": meanVelo,\n        \"stdVelo\": stdVelo,\n        \"proba\": Probas,\n        \"switch\": switch,\n        \"tgt_direction\": Directions,\n        \"SaccDirection\": SaccD,\n        \"SaccTrial\": TS,\n        \"StimuOn\": SON,\n        \"StimuOff\": SOFF,\n    }\n)\nsubjects = []\nfor nc,af in zip(namesCat,allFiles):\n    for name, file in zip(nc, af):\n        for i in range(len(file)):\n            subjects.append(name)\ndf[\"name\"] = subjects", "outhist_cell": "LBiWLFEt1r", "is_md": 0, "cmd_opts": " --cell_id=NONE -s", "import_complete": 1, "terminal": "nvimterm"}